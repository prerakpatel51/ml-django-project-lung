{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = []\n",
    "# val_data = []\n",
    "\n",
    "# for folder in os.listdir(data_path):\n",
    "#     folder_path = os.path.join(data_path, folder)\n",
    "#     file = os.listdir(folder_path)\n",
    "#     num_train = int(0.8 * len(file))\n",
    "#     files_train = random.sample(file, num_train)\n",
    "#     files_val = list(set(file) - set(files_train))\n",
    "    \n",
    "#     for file in files_train:\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "#         img = cv2.imread(file_path)\n",
    "#         img = cv2.resize(img, (224,224))\n",
    "#         train_data.append((img, folder))\n",
    "        \n",
    "#     for file in files_val:\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "#         img = cv2.imread(file_path)\n",
    "#         img = cv2.resize(img, (224,224))\n",
    "#         val_data.append((img, folder))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "data_path = 'train/'\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    # Exclude .DS_Store directory\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    file = os.listdir(folder_path)\n",
    "    num_train = int(0.6 * len(file))\n",
    "    files_train = random.sample(file, num_train)\n",
    "    files_val = list(set(file) - set(files_train))\n",
    "    \n",
    "    for file in files_train:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        train_data.append((img, folder))\n",
    "        \n",
    "    for file in files_val:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        val_data.append((img, folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "plt.suptitle('LABELS OF EACH IMAGE')\n",
    "\n",
    "for (img, label), ax in zip(random.sample(train_data, 8), axes.flatten()):\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.grid(False)\n",
    "    ax.set_title(label)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB) )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# train_data = [(preprocess_input(input), label) for input, label in train_data]\n",
    "# val_data = [(preprocess_input(input), label) for input, label in val_data]\n",
    "\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_val, y_val = zip(*val_data)\n",
    "\n",
    "X_train = preprocess_input(np.array(X_train))\n",
    "X_val = preprocess_input(np.array(X_val))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train_encoded, num_classes)\n",
    "y_val_one_hot = to_categorical(y_val_encoded, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 7\n",
    "BATCH_SIZE = 64\n",
    "history = model.fit(X_train, y_train_one_hot, validation_data=(X_val, y_val_one_hot),\n",
    "                   epochs = EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.save('pneumonia.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 12:55:07.102089: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 26s 210ms/step - loss: 0.6074 - accuracy: 0.8781 - val_loss: 0.6114 - val_accuracy: 0.7427\n",
      "Epoch 2/20\n",
      "115/115 [==============================] - 22s 186ms/step - loss: 0.5005 - accuracy: 0.9104 - val_loss: 0.5776 - val_accuracy: 0.7427\n",
      "Epoch 3/20\n",
      "115/115 [==============================] - 21s 185ms/step - loss: 0.4334 - accuracy: 0.9145 - val_loss: 0.5703 - val_accuracy: 0.7427\n",
      "Epoch 4/20\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.3957 - accuracy: 0.9014 - val_loss: 0.5772 - val_accuracy: 0.7427\n",
      "Epoch 5/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.3496 - accuracy: 0.9197 - val_loss: 0.5918 - val_accuracy: 0.7427\n",
      "Epoch 6/20\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.3270 - accuracy: 0.9181 - val_loss: 0.5586 - val_accuracy: 0.7688\n",
      "Epoch 7/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.2920 - accuracy: 0.9342 - val_loss: 0.6871 - val_accuracy: 0.5249\n",
      "Epoch 8/20\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.2795 - accuracy: 0.9288 - val_loss: 0.7082 - val_accuracy: 0.5249\n",
      "Epoch 9/20\n",
      "115/115 [==============================] - 22s 187ms/step - loss: 0.2598 - accuracy: 0.9367 - val_loss: 0.5300 - val_accuracy: 0.7427\n",
      "Epoch 10/20\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.2320 - accuracy: 0.9474 - val_loss: 0.3119 - val_accuracy: 0.8870\n",
      "Epoch 11/20\n",
      "115/115 [==============================] - 22s 187ms/step - loss: 0.2226 - accuracy: 0.9485 - val_loss: 0.1967 - val_accuracy: 0.9585\n",
      "Epoch 12/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.2320 - accuracy: 0.9348 - val_loss: 0.2185 - val_accuracy: 0.9419\n",
      "Epoch 13/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.2033 - accuracy: 0.9510 - val_loss: 0.3421 - val_accuracy: 0.8614\n",
      "Epoch 14/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.1869 - accuracy: 0.9556 - val_loss: 0.1967 - val_accuracy: 0.9432\n",
      "Epoch 15/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.1791 - accuracy: 0.9564 - val_loss: 0.4824 - val_accuracy: 0.7631\n",
      "Epoch 16/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.1662 - accuracy: 0.9603 - val_loss: 0.2521 - val_accuracy: 0.9215\n",
      "Epoch 17/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.1605 - accuracy: 0.9570 - val_loss: 0.3622 - val_accuracy: 0.8365\n",
      "Epoch 18/20\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.1497 - accuracy: 0.9633 - val_loss: 0.1972 - val_accuracy: 0.9368\n",
      "Epoch 19/20\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.1270 - accuracy: 0.9723 - val_loss: 0.1317 - val_accuracy: 0.9693\n",
      "Epoch 20/20\n",
      "115/115 [==============================] - 22s 187ms/step - loss: 0.1263 - accuracy: 0.9704 - val_loss: 0.1806 - val_accuracy: 0.9425\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.optimizers.legacy.Adam import Adam.\n",
    "data_path = 'train/'\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "# Adjust the percentage of data used for training\n",
    "train_percentage = 0.7  # 60% for training\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    file = os.listdir(folder_path)\n",
    "    \n",
    "    num_train = int(train_percentage * len(file))\n",
    "    files_train = random.sample(file, num_train)\n",
    "    files_val = list(set(file) - set(files_train))\n",
    "    \n",
    "    for file in files_train:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        train_data.append((img, folder))\n",
    "        \n",
    "    for file in files_val:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        val_data.append((img, folder))\n",
    "\n",
    "# Larger pre-trained model for knowledge distillation\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Smaller model for distillation\n",
    "small_model = MobileNet(weights=None, input_shape=(224, 224, 3), classes=2)\n",
    "distillation_layer = GlobalAveragePooling2D()(base_model.output)\n",
    "distillation_layer = Dense(512, activation='relu')(distillation_layer)\n",
    "distillation_layer = Model(inputs=base_model.input, outputs=distillation_layer)\n",
    "\n",
    "# Final output layer for small model\n",
    "predictions = Dense(2, activation='softmax')(small_model.output)\n",
    "\n",
    "# Combine small model with distillation layer\n",
    "model = Model(inputs=small_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prepare data for training\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_val, y_val = zip(*val_data)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train_encoded, 2)\n",
    "y_val_one_hot = to_categorical(y_val_encoded, 2)\n",
    "\n",
    "# Train the model with knowledge distillation\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "history = model.fit(X_train, y_train_one_hot, validation_data=(X_val, y_val_one_hot),\n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('small_pneumonia_model3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x319740d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x319740d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 303ms/step\n",
      "Predicted class: [1]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('small_pneumonia_model3.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'person1_bacteria_2.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))  # Resize to match the input size of the model\n",
    "image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "image = preprocess_input(image)  # Preprocess the image\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(image)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 852810,
     "sourceId": 1454699,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
